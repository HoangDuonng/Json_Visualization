{"version":3,"file":"static/chunks/44223.86e8665d4393bccc.js","mappings":"mGACA,mEACA,kBACA,0CACA,6DACA,IAAe,6BAAoC,eAEnD,4BACA,CAAC,mBACD,kBACA,UACC,EACD,8DACA,mCAA0C,sBAA4B,CACtE,CAAC,eACD,YACA,CAAC,CACD,uCACA,4BACA,SACA,6FAEA,OADA,OACA,CACA,EACA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,QAAgB,QAChB,MAAmB,EAAQ,KAAU,EACrC,EAAgB,EAAQ,KAAO,CADL,CAE1B,EAAoB,EAAQ,KAAa,CADlB,CAEvB,IAA2B,EAAQ,IADR,CACiB,GA0a5C,SA1akC,CA0alB,CAzahB,YACA,6JACA,wCACA,0CACA,qBACA,iCACA,mBACA,EA0DA,qBACA,cACA,aACA,4BAEA,uCAA+F,EAAY,GAC3G,qBACA,QAEA,CACA,KAHsC,CAGtC,EACA,CAAa,EAEb,CACA,CAJ6B,SAQ7B,YACA,8CACA,qBAEA,aACA,SAEA,CACA,CA8CA,oBACA,OAEA,cACA,iCACA,0CACA,SAEA,GANA,GA6BA,kBAnJA,EAoJA,MApBA,OAEA,mBACA,4BAIA,oBAEA,eAGA,QACA,CAAS,EAZT,GAoBA,MAEA,EArJA,KAFA,EAPA,uBA6JA,EA7JA,IASA,OACA,GAGA,yBACA,SAaA,OAYA,EAVA,WAEA,GAQA,EAVA,EAWA,EAXA,SAWA,cAEA,uCACA,EACA,IACA,EACS,GAdT,6CAEA,QACA,EArBA,GAIA,uBA6IA,WACA,SACA,oBAEA,kBACA,SAGA,SACA,aAA6C,EAAgB,GAC7D,eACA,qBACA,UAGA,QACA,CAAa,EACb,mBAEA,SADA,KAGA,CAEA,SADA,KAEA,CA8GA,cACA,yBAAmD,MACnD,mDACA,kBAEA,WACA,YAEA,0BACA,gBAGA,iDAEA,CAuCA,cACA,uBAeA,OAbA,8BAEA,qBAIA,gCACA,8BACA,YACA,4CAEA,UAEA,CACA,CA4CA,OACA,QApBA,gBApJA,EApJA,EAXA,EAuBA,EAgRA,MA9QA,EA+QA,IA4BA,OAfA,kBACA,QAdA,GAxIA,CADA,EAgKA,SApMA,UACA,mBAOA,GALA,2BACA,+BACA,CAAa,EACb,4BAEA,SA3BA,GACA,uBACA,4BAEA,iBADA,yBAEA,SAIA,QACA,EAiBA,GACA,cAIA,MACA,cAGA,SAEA,kBADA,IACA,CAGA,CACA,QACA,EAsKA,CACA,kBACA,UACA,UACA,eACA,IA9JA,mCAmCA,QACA,QA2FA,CA5FA,EAjCA,EAiCA,EAjCA,eAkCA,KACA,cACA,8BACA,wDACA,wBAEA,KAvBA,MACA,CAsBA,0CAvBA,EAwBA,EAvBA,yBAuBA,EArBA,mBAGA,aAGA,KAEA,CAFgD,CALhD,sBAqBA,CACA,SACA,CAAS,EACT,GA3CA,QAEA,WAkFA,KACA,0BACA,oBACA,gBAEA,sCACA,qCAGA,CACA,QACA,EA9FA,EAiEA,cACA,sBACA,oBACA,gBAEA,sBACA,eAGA,CACA,QACA,EA5EA,IAEA,oBAEA,OADA,IAEA,CAAa,EAqHb,0BAlHS,sBAlKT,EAmKA,EAjKA,iBACA,+CACA,WACA,EAAa,EAhBb,EAkBA,EAjBA,oBACA,mDACA,iBACA,YAmBA,EAjBA,EAmBA,+BACA,wBACA,gBACA,QASA,OAPA,cACA,qBAEA,0BAEA,2BAEA,CACA,CAAS,EACT,wBAgQA,EA/PA,GAgQA,wBAEA,2BACA,uCACA,CAyBA,CAGA,CACA,iBC5UA,cACA,eAOA,GACA,YAAoB,WAAe,KACnC,oBACA,SADA,MACA,SACA,QACA,CACA,SACA,EAdA,GACA,OACA,WACA,iDACA,sBACA,CACA,CA3HA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,OAAe,CAAG,cAAoB,QAyCtC,cAAoB,CApCpB,gBACA,MACA,YAEA,aAAY,qBAA2B,KACvC,yCACA,yCACA,uCAUA,sBACA,yBACA,wBAIA,iBAHA,CAIA,MACA,2CAEA,mBAEA,iDAEA,QACA,KAzBA,CACA,IAAgB,OAAe,KAC/B,qBAEA,2BACA,iBAGA,MACA,CAkBA,QACA,EAeA,SAAe,CATf,gBACA,KAGA,OACA,uCACA,MAJA,uCAKA,gBAIA,SACA,aAAY,qBAA2B,KAEvC,qFACA,SAEA,SACA,kBAEA,wEAKA,OAHA,cAEA,YACA,EAEA,6DAGA,OADA,uBACA,EAEA,+DACA,IAAoB,OAAe,KAEnC,SADA,aAKA,UAGA,OADA,OACA,OAIA,aATA,QAYA,WACA,MACA,qBACA,kBAEA,4BAEA,OADA,OACA,EAGA,sBAEA,MAGA,OAEA,QACA,EA5DA,MACA,yBC5DA,mEACA,kBACA,0CACA,6DACA,IAAe,6BAAoC,eAEnD,4BACA,CAAC,mBACD,kBACA,UACC,EACD,8DACA,mCAA0C,sBAA4B,CACtE,CAAC,eACD,YACA,CAAC,CACD,uCACA,4BACA,SACA,6FAEA,OADA,OACA,CACA,EACA,yCACA,iFACA,EACA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,gBAAwB,CAAG,UAAgB,QAC3C,QAA2B,EAAQ,KAAS,GAQ5C,SARkC,EAQlC,KACA,iBACA,6BACA,SAsBA,SACA,6BAEA,eAwDA,YACA,EACA,QAEA,CACA,EA7DA,UAEA,8GACA,mBAEA,6CAEA,KAkBA,UACA,EAnBA,OAkBA,EAlBA,KAkBA,EAlBA,EAmBA,MADA,EAlBA,GAoBA,SAGA,kCAEA,KAGA,WACA,+BACA,IAEA,mBAiBA,YACA,EACA,QAEA,IArBA,YAEA,wBAbA,uCArBA,QAEA,uDACA,GAGA,CACA,CAAK,EACL,mBACA,EAzCA,QAEA,EACA,CAQA,gBACA,WACA,gBACA,6BAEA,OAEA,GAEA,CAiDA,uBACA,mBACA,uBAEA,CACA,CAaA,cACA,OACA,sBACA,uBACA,sBACA,kCACA,oBACA,qBACA,QAAyB,CAEzB,CA3GA,EAAa,EAAQ,KAAS,KAc9B,OAdoB,GAcJ,GAiBhB,kBAAwB,oBC3DxB,UAAgB,CAAG,UAAgB,QACnC,MAAoB,EAAQ,KAAa,EACzC,EAAmB,EAAQ,IAAY,EADZ,EAER,EAAQ,KAAY,EACvC,EAAgB,EAAQ,KAAS,CADP,CAQ1B,UAPuB,CACvB,cACA,iCAAmE,EAGnE,MADA,+CACA,4BACA,EAQA,UAAgB,CANhB,cACA,iCAAmE,EAGnE,MADA,+CACA,4BACA,iBClBA,qCAA6C,CAAE,SAAa,EAAC,uBCA7D,mEACA,kBACA,0CACA,6DACA,IAAe,6BAAoC,eAEnD,4BACA,CAAC,mBACD,kBACA,UACC,EACD,8DACA,mCAA0C,sBAA4B,CACtE,CAAC,eACD,YACA,CAAC,CACD,uCACA,4BACA,SACA,6FAEA,OADA,OACA,CACA,EACA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,QAAgB,QAChB,MAAmB,EAAQ,KAAU,EACrC,EAAoB,EAAQ,KAAa,CADf,CAE1B,IAA2B,EAAQ,IADR,CACiB,GAuV5C,SAvVkC,CAuVlB,CAtVhB,YACA,qJAIA,oBAEA,CADA,OACA,oBACA,aACA,iBACA,UAEA,CACA,CAwOA,qBACA,4BACA,SAEA,CACA,CAyBA,cACA,sCAEA,2CAEA,gCAEA,CACA,CAuDA,OACA,QATA,gBA3HA,EAuFA,EA0CA,MAxCA,CAzFA,EA9LA,YACA,SACA,MA6T4C,WA7T5C,CACA,8BACA,WACA,OACA,EAAa,OAUb,GALA,EADA,KACA,aACA,WACA,OACA,EAAa,EAEb,QACA,aACA,CAD2C,CAC3C,gCACA,CAEA,OACA,QACA,eACA,eAEA,EAaA,YAEA,kDACA,uBACA,gBACA,yBACA,YACA,EACA,iBAEA,kBAUA,GARA,OAEA,cAEA,gBAIA,EADA,6BACA,yCACA,6BA0BA,iCAGA,kCACA,UAEA,WACA,SACA,MACA,gCAEA,uBACA,yEAYA,gDACA,sCAUA,oEAGA,sCACA,eACA,kBACA,yBACA,2BACA,UAEA,0EACA,kEAEA,yBACA,uBAGA,qGAMA,sEAEA,sCACA,iBACA,CADuD,CACvD,uBACA,uBAEA,gDACA,uCAEA,sCACA,yBACA,kBACA,oBAEA,iEAEA,KACA,2BACA,QACA,MACA,6CACA,8CACA,gBAEA,oCACA,kBAEA,6CACA,uCAGA,yBACA,kBACA,uBAtCA,yBACA,kBACA,oBA7BA,eACA,yBACA,kBAEA,6CACA,+BAA+D,GApB/D,CAEA,2CAEA,oCAEA,UACA,KACA,iBACA,kBACA,gDA5CA,uCAGA,sBAGA,WAIA,kCAIA,WAEA,UACA,KACA,iBACA,kBACA,2CAiGA,IAEA,0BACA,CACA,QACA,EA3JA,WACA,gBA2RA,IA5HA,eACA,GADoC,UACpC,SAGA,gCAkFA,EAhFA,GAkFA,+BAxCA,IAyCA,WAIA,IADA,EAXA,CAUA,QAVA,8BAeA,OAhDA,EAgDA,eAhDA,EAgDA,EA9CA,qBA7BA,MAEA,EA6BA,GA7BA,WAgFA,GACA,IACA,6DACA,SAEA,WAEA,oBACA,gBAEA,QACA,CACA,SACA,QACA,CACA,EAjGA,EA+BA,CAvCA,WAaA,6BAGA,gBAGA,SALA,GA0BA,IAEA,gCACA,CACA,SAEA,QACA,CACA,CAAS,GAAI,GAoCb,kBACA,CAAS,IA+BT,CAGA,CACA,iBCjXA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,mBAA2B,CAAG,SAAe,CAAG,QAAc,QAI9D,QAAc,CAHd,YACA,uBAMA,SAAe,CAHf,YACA,qBACA,EAUA,qBAA2B,CAH3B,YACA,+FChBA,qCAA6C,CAAE,SAAa,EAC5D,WAAiB,CAAG,SAAe,CAAG,QAAc,CAAG,iBAAuB,CAAG,SAAe,CAAG,aAAmB,CAAG,QAAc,CAAG,UAAgB,CAAG,UAAgB,CAAG,UAAgB,CAAG,QAAc,CAAG,gBAAsB,CAAG,mBAAyB,CAAG,cAAoB,CAAG,0BAAgC,CAAG,sBAA4B,CAAG,wBAA8B,CAAG,UAAgB,CAAG,UAAgB,CAAG,iBAAuB,CAAG,iBAAuB,QAC1d,MAAmB,EAAQ,KAAU,EACrC,EAAoB,EAAQ,KAAa,CADf,CAE1B,MAA4B,EAAE,EADH,EACO,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,GA+ClE,cACA,oCACA,CAgCA,cACA,yBACA,CA+EA,cACA,eACA,CAEA,cACA,iBACA,CAQA,gBACA,kCACA,CAhKA,iBAAuB,CAZvB,YACA,OACA,4BACA,KACA,WACA,oEACA,iEACA,6DACA,CAAS,CACT,gDAA8D,CAC9D,CACA,EAkBA,iBAAuB,CAXvB,YACA,OACA,4BACA,KACA,WACA,oEACA,iEACA,6DACA,CAAS,CAET,EASA,UAAgB,CAPhB,gBACA,MACA,eAA2B,gBAA4B,EAAE,EAAK,IAC9D,SACA,gCACA,QACA,EAQA,UAAgB,GAWhB,wBAA8B,CAL9B,cACA,+BAEA,mDAUA,sBAA4B,CAH5B,YACA,gBACA,EASA,0BAAgC,CAJhC,cACA,cACA,cACA,EAQA,cAAoB,GAOpB,mBAAyB,CAHzB,YACA,yBACA,EAWA,gBAAsB,CAHtB,gBACA,yBACA,EA2CA,QAAc,CAPd,cACA,SAIA,OAHA,kBAtBA,EACA,EADA,qBAuBA,KAtBA,IAsBA,GArBA,2BACA,cACA,IAmBA,GAlBA,uBAkBA,EAlBA,GACA,CAAS,GAET,gCAEA,gBAaA,EAbA,IAIA,UAUA,CAAK,EACL,CACA,EAQA,UAAgB,CAHhB,YACA,uBACA,EAQA,UAAgB,CAHhB,YACA,wBACA,EAKA,UAAgB,CAHhB,YACA,wBACA,EAKA,QAAc,GAId,aAAmB,GAMnB,SAAe,CALf,YAGA,0DACA,EAKA,iBAAuB,GAIvB,QAAc,CAHd,YACA,uBAkBA,SAAe,CAff,YAEA,UACA,gBAGA,YA9LkE,IA8LlE,CACA,SACA,YAAwB,WAAkB,GAhMwB,IAiMlE,0BAjMkE,MAmMlE,QACA,CACA,sCACA,EAUA,WAAiB,CAJjB,YACA,gBACA,QACA,iBCnNA,qCAA6C,CAAE,SAAa,EAAC,EAC7D,QAAgB,CAAG,wBAA8B,CAAG,wBAA8B,CAAG,QAAc,QACnG,QAAc,EACd,4DACA,UACA,uCACA,gEACA,uDACA,CAAK,CACL,UACA,uCACA,uCACA,CACA,EACA,wBAA8B,EAC9B,sBACA,0BACA,WACA,UACA,SACA,QACA,CAAK,CACL,uBACA,0BACA,YACA,eACA,uBACA,sBACA,iBACA,uBACA,cACA,mBACA,oBACA,gBACA,wBACA,mBACA,gBACA,8BAAmC,CACnC,EACA,wBAA8B,EAC9B,WACA,UACA,SACA,QACA,CAAK,CACL,YACA,uBACA,mBACA,mBACA,EACA,UAAgB","sources":["webpack://_N_E/./node_modules/json-2-csv/lib/json2csv.js","webpack://_N_E/./node_modules/doc-path/lib/path.js","webpack://_N_E/./node_modules/deeks/lib/deeks.js","webpack://_N_E/./node_modules/json-2-csv/lib/converter.js","webpack://_N_E/./node_modules/deeks/lib/types.js","webpack://_N_E/./node_modules/json-2-csv/lib/csv2json.js","webpack://_N_E/./node_modules/deeks/lib/utils.js","webpack://_N_E/./node_modules/json-2-csv/lib/utils.js","webpack://_N_E/./node_modules/json-2-csv/lib/constants.js"],"sourcesContent":["'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n    const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'), crlfSearchRegex = /\\r?\\n|\\r/, customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null, expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays, deeksOptions = {\n        arrayIndexesAsKeys: options.arrayIndexesAsKeys,\n        expandNestedObjects: options.expandNestedObjects,\n        expandArrayObjects: expandingWithoutUnwinding,\n        ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n        escapeNestedDots: true,\n    };\n    /** HEADER FIELD FUNCTIONS **/\n    /**\n     * Returns the list of data field names of all documents in the provided list\n     */\n    function getFieldNameList(data) {\n        // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n        return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n    }\n    /**\n     * Processes the schemas by checking for schema differences, if so desired.\n     * If schema differences are not to be checked, then it resolves the unique\n     * list of field names.\n     */\n    function processSchemas(documentSchemas) {\n        // If there are no document schemas then there is nothing to diff and no unique fields to get\n        if (documentSchemas.length === 0) {\n            return [];\n        }\n        // If the user wants to check for the same schema (regardless of schema ordering)\n        if (options.checkSchemaDifferences) {\n            return checkSchemaDifferences(documentSchemas);\n        }\n        else {\n            // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n            const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n            return uniqueFieldNames;\n        }\n    }\n    /**\n     * This function performs the schema difference check, if the user specifies that it should be checked.\n     * If there are no field names, then there are no differences.\n     * Otherwise, we get the first schema and the remaining list of schemas\n     */\n    function checkSchemaDifferences(documentSchemas) {\n        // have multiple documents - ensure only one schema (regardless of field ordering)\n        const firstDocSchema = documentSchemas[0], restOfDocumentSchemas = documentSchemas.slice(1), schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n        // If there are schema inconsistencies, throw a schema not the same error\n        if (schemaDifferences) {\n            throw new Error(constants_1.errors.json2csv.notSameSchema);\n        }\n        return firstDocSchema;\n    }\n    /**\n     * Computes the number of schema differences\n     */\n    function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n        return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n            // If there is a difference between the schemas, increment the counter of schema inconsistencies\n            const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n            return numberOfDifferences > 0\n                ? schemaDifferences + 1\n                : schemaDifferences;\n        }, 0);\n    }\n    /**\n     * If so specified, this filters the detected key paths to exclude any keys that have been specified\n     */\n    function filterExcludedKeys(keyPaths) {\n        if (options.excludeKeys) {\n            return keyPaths.filter((keyPath) => {\n                for (const excludedKey of options.excludeKeys) {\n                    // Only match if the excludedKey appears at the beginning of the string so we don't accidentally match a key farther down in a key path\n                    const regex = excludedKey instanceof RegExp ? excludedKey : new RegExp(`^${excludedKey}`);\n                    if (excludedKey === keyPath || keyPath.match(regex)) {\n                        return false; // Exclude the key\n                    }\n                }\n                return true; // Otherwise, include the key\n            });\n        }\n        return keyPaths;\n    }\n    /**\n     * If so specified, this sorts the header field names alphabetically\n     */\n    function sortHeaderFields(fieldNames) {\n        if (options.sortHeader && typeof options.sortHeader === 'function') {\n            return fieldNames.sort(options.sortHeader);\n        }\n        else if (options.sortHeader) {\n            return fieldNames.sort();\n        }\n        return fieldNames;\n    }\n    /**\n     * Trims the header fields, if the user desires them to be trimmed.\n     */\n    function trimHeaderFields(params) {\n        if (options.trimHeaderFields) {\n            params.headerFields = params.headerFields.map((field) => field.split('.')\n                .map((component) => component.trim())\n                .join('.'));\n        }\n        return params;\n    }\n    /**\n     * Wrap the headings, if desired by the user.\n     */\n    function wrapHeaderFields(params) {\n        // only perform this if we are actually prepending the header\n        if (options.prependHeader) {\n            params.headerFields = params.headerFields.map(function (headingKey) {\n                return wrapFieldValueIfNecessary(headingKey);\n            });\n        }\n        return params;\n    }\n    /**\n     * Generates the CSV header string by joining the headerFields by the field delimiter\n     */\n    function generateCsvHeader(params) {\n        // #185 - generate a keys list to avoid finding native Map() methods\n        const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n        params.header = params.headerFields\n            .map(function (field) {\n            let headerKey = field;\n            // If a custom field title was provided for this field, use that\n            if (fieldTitleMapKeys.includes(field)) {\n                headerKey = options.fieldTitleMap[field];\n            }\n            else if (!options.escapeHeaderNestedDots) {\n                // Otherwise, if the user doesn't want nested dots in keys to be escaped, then unescape them\n                headerKey = headerKey.replace(/\\\\\\./g, '.');\n            }\n            return headerKey;\n        })\n            .join(options.delimiter.field);\n        return params;\n    }\n    function convertKeysToHeaderFields() {\n        if (!options.keys)\n            return [];\n        return options.keys.map((key) => {\n            if (typeof key === 'object' && 'field' in key) {\n                options.fieldTitleMap[key.field] = key.title ?? key.field;\n                return key.field;\n            }\n            return key;\n        });\n    }\n    function extractWildcardMatchKeys() {\n        if (!options.keys)\n            return [];\n        return options.keys.flatMap(item => {\n            if (typeof item === 'string') {\n                // Exclude plain strings that were passed in options.keys\n                return [];\n            }\n            else if (item?.wildcardMatch) {\n                // Return \"field\" value for objects with wildcardMatch: true\n                return item.field;\n            }\n            // Exclude other objects\n            return [];\n        });\n    }\n    /**\n     * Retrieve the headings for all documents and return it.\n     * This checks that all documents have the same schema.\n     */\n    function retrieveHeaderFields(data) {\n        const wildcardMatchKeys = extractWildcardMatchKeys();\n        const keyStrings = convertKeysToHeaderFields();\n        const fieldNames = getFieldNameList(data);\n        const processed = processSchemas(fieldNames);\n        if (options.keys) {\n            options.keys = keyStrings;\n            const matchedKeys = keyStrings.flatMap((userProvidedKey) => {\n                // If this is not a wildcard matched key, then just return and include it in the resulting key list\n                if (!wildcardMatchKeys.includes(userProvidedKey)) {\n                    return userProvidedKey;\n                }\n                // Otherwise, identify all detected keys that match with the provided wildcard key:\n                const matches = [];\n                const regex = new RegExp(`^${userProvidedKey}`);\n                for (const detectedKey of processed) {\n                    if (userProvidedKey === detectedKey || detectedKey.match(regex)) {\n                        matches.push(detectedKey);\n                    }\n                }\n                return matches;\n            });\n            if (!options.unwindArrays) {\n                const filtered = filterExcludedKeys(matchedKeys);\n                return sortHeaderFields(filtered);\n            }\n        }\n        const filtered = filterExcludedKeys(processed);\n        return sortHeaderFields(filtered);\n    }\n    /** RECORD FIELD FUNCTIONS **/\n    function stillNeedsUnwind(params) {\n        for (const record of params.records) {\n            for (const field of params.headerFields) {\n                const value = (0, doc_path_1.evaluatePath)(record, field);\n                if (Array.isArray(value)) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n    /**\n     * Unwinds objects in arrays within record objects if the user specifies the\n     * expandArrayObjects option. If not specified, this passes the params\n     * argument through to the next function in the promise chain.\n     *\n     * The `finalPass` parameter is used to trigger one last pass to ensure no more\n     * arrays need to be expanded\n     */\n    function unwindRecordsIfNecessary(params, finalPass = false) {\n        if (options.unwindArrays) {\n            // Unwind each document at each header field\n            params.headerFields.forEach((headerField) => {\n                params.records = utils.unwind(params.records, headerField);\n            });\n            params.headerFields = retrieveHeaderFields(params.records);\n            // Continue unwinding if any nested arrays remain\n            if (stillNeedsUnwind(params)) {\n                return unwindRecordsIfNecessary(params, finalPass);\n            }\n            // Run a final time in case the earlier unwinding exposed additional\n            // arrays to unwind...\n            if (!finalPass) {\n                return unwindRecordsIfNecessary(params, true);\n            }\n            // If keys were provided, set the headerFields back to the provided keys after unwinding:\n            if (options.keys) {\n                const userSelectedFields = convertKeysToHeaderFields();\n                params.headerFields = filterExcludedKeys(userSelectedFields);\n            }\n            return params;\n        }\n        return params;\n    }\n    /**\n     * Main function which handles the processing of a record, or document to be converted to CSV format\n     * This function specifies and performs the necessary operations in the necessary order\n     * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n     * * Order of operations:\n     * - Get fields from provided key list (as array of actual values)\n     * - Convert the values to csv/string representation [possible option here for custom converters?]\n     * - Trim fields\n     * - Determine if they need to be wrapped (& wrap if necessary)\n     * - Combine values for each line (by joining by field delimiter)\n     */\n    function processRecords(params) {\n        params.recordString = params.records.map((record) => {\n            // Retrieve data for each of the headerFields from this record\n            const recordFieldData = retrieveRecordFieldData(record, params.headerFields), \n            // Process the data in this record and return the\n            processedRecordData = recordFieldData.map((fieldValue) => {\n                fieldValue = trimRecordFieldValue(fieldValue);\n                fieldValue = preventCsvInjection(fieldValue);\n                let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n                stringified = wrapFieldValueIfNecessary(stringified);\n                return stringified;\n            });\n            // Join the record data by the field delimiter\n            return generateCsvRowFromRecord(processedRecordData);\n        }).join(options.delimiter.eol);\n        return params;\n    }\n    /**\n     * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n     */\n    function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n        const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n        // If we have an array and it's either empty of full of empty values, then use an empty value representation\n        if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n            return options.emptyFieldValue || '';\n        }\n        else if (filteredRecordFieldValue.length === 1) {\n            // Otherwise, we have an array of actual values...\n            // Since we are expanding array objects, we will want to key in on values of objects.\n            return filteredRecordFieldValue[0]; // Extract the single value in the array\n        }\n        return recordFieldValue;\n    }\n    /**\n     * Gets all field values from a particular record for the given list of fields\n     */\n    function retrieveRecordFieldData(record, fields) {\n        const recordValues = [];\n        fields.forEach((field) => {\n            let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n            if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n                recordFieldValue = options.emptyFieldValue;\n            }\n            else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n                recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n            }\n            recordValues.push(recordFieldValue);\n        });\n        return recordValues;\n    }\n    /**\n     * Converts a record field value to its string representation\n     */\n    function recordFieldValueToString(fieldValue) {\n        const isDate = fieldValue instanceof Date; // store to avoid checking twice\n        if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n            return JSON.stringify(fieldValue);\n        }\n        else if (typeof fieldValue === 'undefined') {\n            return 'undefined';\n        }\n        else if (isDate && options.useDateIso8601Format) {\n            return fieldValue.toISOString();\n        }\n        else {\n            return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n        }\n    }\n    /**\n     * Trims the record field value, if specified by the user's provided options\n     */\n    function trimRecordFieldValue(fieldValue) {\n        if (options.trimFieldValues) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(trimRecordFieldValue);\n            }\n            else if (typeof fieldValue === 'string') {\n                return fieldValue.trim();\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Prevent CSV injection on strings if specified by the user's provided options.\n     * Mitigation will be done by ensuring that the first character doesn't being with:\n     * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n     * More info: https://owasp.org/www-community/attacks/CSV_Injection\n     */\n    function preventCsvInjection(fieldValue) {\n        if (options.preventCsvInjection) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(preventCsvInjection);\n            }\n            else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n                return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Escapes quotation marks in the field value, if necessary, and appropriately\n     * wraps the record field value if it contains a comma (field delimiter),\n     * quotation mark (wrap delimiter), or a line break (CRLF)\n     */\n    function wrapFieldValueIfNecessary(fieldValue) {\n        const wrapDelimiter = options.delimiter.wrap;\n        // eg. includes quotation marks (default delimiter)\n        if (fieldValue.includes(options.delimiter.wrap)) {\n            // add an additional quotation mark before each quotation mark appearing in the field value\n            fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n        }\n        // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n        //   then enclose it in quotation marks (wrap delimiter)\n        if (fieldValue.includes(options.delimiter.field) ||\n            fieldValue.includes(options.delimiter.wrap) ||\n            fieldValue.match(crlfSearchRegex) ||\n            options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n            // wrap the field's value in a wrap delimiter (quotation marks by default)\n            fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n        }\n        return fieldValue;\n    }\n    /**\n     * Generates the CSV record string by joining the field values together by the field delimiter\n     */\n    function generateCsvRowFromRecord(recordFieldValues) {\n        return recordFieldValues.join(options.delimiter.field);\n    }\n    /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n    /**\n     * Performs the final CSV construction by combining the fields in the appropriate\n     * order depending on the provided options values and sends the generated CSV\n     * back to the user\n     */\n    function generateCsvFromComponents(params) {\n        const header = params.header, records = params.recordString, \n        // If we are prepending the header, then add an EOL, otherwise just return the records\n        csv = (options.excelBOM ? constants_1.excelBOM : '') +\n            (options.prependHeader ? header + options.delimiter.eol : '') +\n            records;\n        return csv;\n    }\n    /** MAIN CONVERTER FUNCTION **/\n    /**\n     * Internally exported json2csv function\n     */\n    function convert(data) {\n        // Single document, not an array\n        if (!Array.isArray(data)) {\n            data = [data]; // Convert to an array of the given document\n        }\n        // Retrieve the heading and then generate the CSV with the keys that are identified\n        const headerFields = {\n            headerFields: retrieveHeaderFields(data),\n            records: data,\n            header: '',\n            recordString: '',\n        };\n        const unwinded = unwindRecordsIfNecessary(headerFields);\n        const processed = processRecords(unwinded);\n        const wrapped = wrapHeaderFields(processed);\n        const trimmed = trimHeaderFields(wrapped);\n        const generated = generateCsvHeader(trimmed);\n        return generateCsvFromComponents(generated);\n    }\n    return {\n        convert,\n    };\n};\nexports.Json2Csv = Json2Csv;\n","/**\n * @license MIT\n * doc-path <https://github.com/mrodrig/doc-path>\n * Copyright (c) 2015-present, Michael Rodrigues.\n */\n'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.setPath = exports.evaluatePath = void 0;\n/**\n * Main function that evaluates the path in a particular object\n * @throws {Error} possible error if call stack size is exceeded\n */\nfunction evaluatePath(obj, kp) {\n    if (!obj) {\n        return null;\n    }\n    const { dotIndex, key, remaining } = state(kp);\n    const kpVal = typeof obj === 'object' && kp in obj ? obj[kp] : undefined;\n    const keyVal = typeof obj === 'object' && key in obj ? obj[key] : undefined;\n    if (dotIndex >= 0 && typeof obj === 'object' && !(kp in obj)) {\n        const { key: nextKey } = state(remaining);\n        const nextKeyAsInt = parseInt(nextKey);\n        // If there's an array at the current key in the object, then iterate over those items evaluating the remaining path\n        if (Array.isArray(keyVal) && isNaN(nextKeyAsInt)) {\n            return keyVal.map((doc) => evaluatePath(doc, remaining));\n        }\n        // Otherwise, we can just recur\n        return evaluatePath(keyVal, remaining);\n    }\n    else if (Array.isArray(obj)) {\n        const keyAsInt = parseInt(key);\n        if (kp === key && dotIndex === -1 && !isNaN(keyAsInt)) {\n            return keyVal;\n        }\n        // If this object is actually an array, then iterate over those items evaluating the path\n        return obj.map((doc) => evaluatePath(doc, kp));\n    }\n    else if (dotIndex >= 0 && kp !== key && typeof obj === 'object' && key in obj) {\n        // If there's a field with a non-nested dot, then recur into that sub-value\n        return evaluatePath(keyVal, remaining);\n    }\n    else if (dotIndex === -1 && typeof obj === 'object' && key in obj && !(kp in obj)) {\n        // If the field is here, but the key was escaped\n        return keyVal;\n    }\n    // Otherwise, we can just return value directly\n    return kpVal;\n}\nexports.evaluatePath = evaluatePath;\n/**\n * Main function that performs validation before passing off to _sp\n * @throws {Error} possible error if call stack size is exceeded\n */\nfunction setPath(obj, kp, v) {\n    if (!obj) {\n        throw new Error('No object was provided.');\n    }\n    else if (!kp) {\n        throw new Error('No keyPath was provided.');\n    }\n    return _sp(obj, kp, v);\n}\nexports.setPath = setPath;\n// Helper function that will set the value in the provided object/array.\nfunction _sp(obj, kp, v) {\n    const { dotIndex, key, remaining } = state(kp);\n    // If this is clearly a prototype pollution attempt, then refuse to modify the path\n    if (kp.startsWith('__proto__') || kp.startsWith('constructor') || kp.startsWith('prototype')) {\n        return obj;\n    }\n    if (dotIndex >= 0) {\n        const keyAsInt = parseInt(key);\n        // If there is a '.' in the key path, recur on the subdoc and ...\n        if (typeof obj === 'object' && obj !== null && !(key in obj) && Array.isArray(obj) && !isNaN(keyAsInt)) {\n            // If there's no value at obj[key] then populate an empty object\n            obj[key] = obj[key] ?? {};\n            // Continue iterating on the rest of the key path to set the appropriate value where intended and then return\n            _sp(obj[key], remaining, v);\n            return obj;\n        }\n        else if (typeof obj === 'object' && obj !== null && !(key in obj) && Array.isArray(obj)) {\n            // If this is an array and there are multiple levels of keys to iterate over, recur.\n            obj.forEach((doc) => _sp(doc, kp, v));\n            return obj;\n        }\n        else if (typeof obj === 'object' && obj !== null && !(key in obj) && !Array.isArray(obj)) {\n            const { key: nextKey } = state(remaining);\n            const nextKeyAsInt = parseInt(nextKey);\n            if (!isNaN(nextKeyAsInt)) {\n                // If the current key doesn't exist yet and the next key is a number (likely array index), populate an empty array\n                obj[key] = [];\n            }\n            else if (remaining === '') {\n                // If the remaining key is empty, then a `.` character appeared right at the end of the path and wasn't actually indicating a separate level\n                obj[kp] = v;\n                return obj;\n            }\n            else {\n                // If the current key doesn't exist yet, populate it\n                obj[key] = {};\n            }\n        }\n        _sp(obj[key], remaining, v);\n    }\n    else if (Array.isArray(obj)) {\n        const keyAsInt = parseInt(key);\n        // If the object is an array and this key is an int (likely array index), then set the value directly and return\n        if (kp === key && dotIndex === -1 && !isNaN(keyAsInt)) {\n            obj[key] = v;\n            return obj;\n        }\n        // If this \"obj\" is actually an array, then we can loop over each of the values and set the path\n        obj.forEach((doc) => _sp(doc, remaining, v));\n        return obj;\n    }\n    else {\n        // Otherwise, we can set the path directly\n        obj[key] = v;\n    }\n    return obj;\n}\n// Helper function that returns some information necessary to evaluate or set a path  based on the provided keyPath value\nfunction state(kp) {\n    const dotIndex = findFirstNonEscapedDotIndex(kp);\n    return {\n        dotIndex,\n        key: kp.slice(0, dotIndex >= 0 ? dotIndex : undefined).replace(/\\\\./g, '.'),\n        remaining: kp.slice(dotIndex + 1)\n    };\n}\nfunction findFirstNonEscapedDotIndex(kp) {\n    for (let i = 0; i < kp.length; i++) {\n        const previousChar = i > 0 ? kp[i - 1] : '', currentChar = kp[i];\n        if (currentChar === '.' && previousChar !== '\\\\')\n            return i;\n    }\n    return -1;\n}\n","'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.deepKeysFromList = exports.deepKeys = void 0;\nconst utils = __importStar(require(\"./utils\"));\n__exportStar(require(\"./types\"), exports);\n/**\n * Return the deep keys list for a single document\n * @param object\n * @param options\n * @returns {Array}\n */\nfunction deepKeys(object, options) {\n    const parsedOptions = mergeOptions(options);\n    if (typeof object === 'object' && object !== null) {\n        return generateDeepKeysList('', object, parsedOptions);\n    }\n    return [];\n}\nexports.deepKeys = deepKeys;\n/**\n * Return the deep keys list for all documents in the provided list\n * @param list\n * @param options\n * @returns Array[Array[String]]\n */\nfunction deepKeysFromList(list, options) {\n    const parsedOptions = mergeOptions(options);\n    return list.map((document) => {\n        if (typeof document === 'object' && document !== null) {\n            // if the data at the key is a document, then we retrieve the subHeading starting with an empty string heading and the doc\n            return deepKeys(document, parsedOptions);\n        }\n        return [];\n    });\n}\nexports.deepKeysFromList = deepKeysFromList;\nfunction generateDeepKeysList(heading, data, options) {\n    const keys = Object.keys(data).map((currentKey) => {\n        // If the given heading is empty, then we set the heading to be the subKey, otherwise set it as a nested heading w/ a dot\n        const keyName = buildKeyName(heading, escapeNestedDotsIfSpecified(currentKey, options));\n        // If we have another nested document, recur on the sub-document to retrieve the full key name\n        if (options.expandNestedObjects && utils.isDocumentToRecurOn(data[currentKey]) || (options.arrayIndexesAsKeys && Array.isArray(data[currentKey]) && data[currentKey].length)) {\n            return generateDeepKeysList(keyName, data[currentKey], options);\n        }\n        else if (options.expandArrayObjects && Array.isArray(data[currentKey])) {\n            // If we have a nested array that we need to recur on\n            return processArrayKeys(data[currentKey], keyName, options);\n        }\n        else if (options.ignoreEmptyArrays && Array.isArray(data[currentKey]) && !data[currentKey].length) {\n            return [];\n        }\n        // Otherwise return this key name since we don't have a sub document\n        return keyName;\n    });\n    return utils.flatten(keys);\n}\n/**\n * Helper function to handle the processing of arrays when the expandArrayObjects\n * option is specified.\n * @param subArray\n * @param currentKeyPath\n * @param options\n * @returns {*}\n */\nfunction processArrayKeys(subArray, currentKeyPath, options) {\n    let subArrayKeys = deepKeysFromList(subArray, options);\n    if (!subArray.length) {\n        return options.ignoreEmptyArraysWhenExpanding ? [] : [currentKeyPath];\n    }\n    else if (subArray.length && utils.flatten(subArrayKeys).length === 0) {\n        // Has items in the array, but no objects\n        return [currentKeyPath];\n    }\n    else {\n        subArrayKeys = subArrayKeys.map((schemaKeys) => {\n            if (Array.isArray(schemaKeys) && schemaKeys.length === 0) {\n                return [currentKeyPath];\n            }\n            return schemaKeys.map((subKey) => buildKeyName(currentKeyPath, escapeNestedDotsIfSpecified(subKey, options)));\n        });\n        return utils.unique(utils.flatten(subArrayKeys));\n    }\n}\nfunction escapeNestedDotsIfSpecified(key, options) {\n    if (options.escapeNestedDots) {\n        return key.replace(/\\./g, '\\\\.');\n    }\n    return key;\n}\n/**\n * Function used to generate the key path\n * @param upperKeyName String accumulated key path\n * @param currentKeyName String current key name\n * @returns String\n */\nfunction buildKeyName(upperKeyName, currentKeyName) {\n    if (upperKeyName) {\n        return upperKeyName + '.' + currentKeyName;\n    }\n    return currentKeyName;\n}\nfunction mergeOptions(options) {\n    return {\n        arrayIndexesAsKeys: false,\n        expandNestedObjects: true,\n        expandArrayObjects: false,\n        ignoreEmptyArraysWhenExpanding: false,\n        escapeNestedDots: false,\n        ignoreEmptyArrays: false,\n        ...(options ?? {})\n    };\n}\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.csv2json = exports.json2csv = void 0;\nconst constants_1 = require(\"./constants\");\nconst json2csv_1 = require(\"./json2csv\");\nconst csv2json_1 = require(\"./csv2json\");\nconst utils_1 = require(\"./utils\");\nfunction json2csv(data, options) {\n    const builtOptions = (0, utils_1.buildJ2COptions)(options ?? {});\n    // Validate the parameters before calling the converter's convert function\n    (0, utils_1.validate)(data, utils_1.isObject, constants_1.errors.json2csv);\n    return (0, json2csv_1.Json2Csv)(builtOptions).convert(data);\n}\nexports.json2csv = json2csv;\nfunction csv2json(data, options) {\n    const builtOptions = (0, utils_1.buildC2JOptions)(options ?? {});\n    // Validate the parameters before calling the converter's convert function\n    (0, utils_1.validate)(data, utils_1.isString, constants_1.errors.csv2json);\n    return (0, csv2json_1.Csv2Json)(builtOptions).convert(data);\n}\nexports.csv2json = csv2json;\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\n","'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Csv2Json = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Csv2Json = function (options) {\n    const escapedWrapDelimiterRegex = new RegExp(options.delimiter.wrap + options.delimiter.wrap, 'g'), excelBOMRegex = new RegExp('^' + constants_1.excelBOM), valueParserFn = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : JSON.parse;\n    /**\n     * Trims the header key, if specified by the user via the provided options\n     */\n    function processHeaderKey(headerKey) {\n        headerKey = removeWrapDelimitersFromValue(headerKey);\n        if (options.trimHeaderFields) {\n            return headerKey.split('.')\n                .map((component) => component.trim())\n                .join('.');\n        }\n        return headerKey;\n    }\n    /**\n     * Generate the JSON heading from the CSV\n     */\n    function retrieveHeading(lines) {\n        let headerFields = [];\n        if (options.headerFields) {\n            headerFields = options.headerFields.map((headerField, index) => ({\n                value: processHeaderKey(headerField),\n                index\n            }));\n        }\n        else {\n            // Generate and return the heading keys\n            const headerRow = lines[0];\n            headerFields = headerRow.map((headerKey, index) => ({\n                value: processHeaderKey(headerKey),\n                index\n            }));\n            // If the user provided keys, filter the generated keys to just the user provided keys so we also have the key index\n            if (options.keys) {\n                const keys = options.keys; // TypeScript type checking work around to get it to recognize the option is not undefined\n                headerFields = headerFields.filter((headerKey) => keys.includes(headerKey.value));\n            }\n        }\n        return {\n            lines,\n            headerFields,\n            recordLines: [],\n        };\n    }\n    /**\n     * Removes the Excel BOM value, if specified by the options object\n     */\n    function stripExcelBOM(csv) {\n        if (options.excelBOM) {\n            return csv.replace(excelBOMRegex, '');\n        }\n        return csv;\n    }\n    /**\n     * Helper function that splits a line so that we can handle wrapped fields\n     */\n    function splitLines(csv) {\n        // Parse out the line...\n        const lines = [], lastCharacterIndex = csv.length - 1, eolDelimiterLength = options.delimiter.eol.length, stateVariables = {\n            insideWrapDelimiter: false,\n            parsingValue: true,\n            justParsedDoubleQuote: false,\n            startIndex: 0\n        };\n        let splitLine = [], character, charBefore, charAfter, nextNChar, index = 0;\n        // Loop through each character in the line to identify where to split the values\n        while (index < csv.length) {\n            // Current character\n            character = csv[index];\n            // Previous character\n            charBefore = index ? csv[index - 1] : '';\n            // Next character\n            charAfter = index < lastCharacterIndex ? csv[index + 1] : '';\n            // Next n characters, including the current character, where n = length(EOL delimiter)\n            // This allows for the checking of an EOL delimiter when if it is more than a single character (eg. '\\r\\n')\n            nextNChar = utils.getNCharacters(csv, index, eolDelimiterLength);\n            if ((nextNChar === options.delimiter.eol && !stateVariables.insideWrapDelimiter ||\n                index === lastCharacterIndex) && charBefore === options.delimiter.field) {\n                // If we reached an EOL delimiter or the end of the csv and the previous character is a field delimiter...\n                // If the start index is the current index (and since the previous character is a comma),\n                //   then the value being parsed is an empty value accordingly, add an empty string\n                if (nextNChar === options.delimiter.eol && stateVariables.startIndex === index) {\n                    splitLine.push('');\n                }\n                else if (character === options.delimiter.field) {\n                    // If we reached the end of the CSV, there's no new line, and the current character is a comma\n                    // then add an empty string for the current value\n                    splitLine.push('');\n                }\n                else {\n                    // Otherwise, there's a valid value, and the start index isn't the current index, grab the whole value\n                    splitLine.push(csv.substring(stateVariables.startIndex));\n                }\n                // Since the last character is a comma, there's still an additional implied field value trailing the comma.\n                //   Since this value is empty, we push an extra empty value\n                splitLine.push('');\n                // Finally, push the split line values into the lines array and clear the split line\n                lines.push(splitLine);\n                splitLine = [];\n                stateVariables.startIndex = index + eolDelimiterLength;\n                stateVariables.parsingValue = true;\n                stateVariables.insideWrapDelimiter = charAfter === options.delimiter.wrap;\n            }\n            else if (index === lastCharacterIndex && character === options.delimiter.field) {\n                // If we reach the end of the CSV and the current character is a field delimiter\n                // Parse the previously seen value and add it to the line\n                const parsedValue = csv.substring(stateVariables.startIndex, index);\n                splitLine.push(parsedValue);\n                // Then add an empty string to the line since the last character being a field delimiter indicates an empty field\n                splitLine.push('');\n                lines.push(splitLine);\n            }\n            else if (index === lastCharacterIndex || nextNChar === options.delimiter.eol &&\n                // if we aren't inside wrap delimiters or if we are but the character before was a wrap delimiter and we didn't just see two\n                (!stateVariables.insideWrapDelimiter ||\n                    stateVariables.insideWrapDelimiter && charBefore === options.delimiter.wrap && !stateVariables.justParsedDoubleQuote)) {\n                // Otherwise if we reached the end of the line or csv (and current character is not a field delimiter)\n                const toIndex = index !== lastCharacterIndex || charBefore === options.delimiter.wrap ? index : undefined;\n                // Retrieve the remaining value and add it to the split line list of values\n                splitLine.push(csv.substring(stateVariables.startIndex, toIndex));\n                // Finally, push the split line values into the lines array and clear the split line\n                lines.push(splitLine);\n                splitLine = [];\n                stateVariables.startIndex = index + eolDelimiterLength;\n                stateVariables.parsingValue = true;\n                stateVariables.insideWrapDelimiter = charAfter === options.delimiter.wrap;\n            }\n            else if (character === options.delimiter.wrap && charBefore === options.delimiter.field &&\n                !stateVariables.insideWrapDelimiter && !stateVariables.parsingValue) {\n                // If we reached a wrap delimiter after a comma and we aren't inside a wrap delimiter\n                stateVariables.startIndex = index;\n                stateVariables.insideWrapDelimiter = true;\n                stateVariables.parsingValue = true;\n                // If the next character(s) are an EOL delimiter, then skip them so we don't parse what we've seen as another value\n                if (utils.getNCharacters(csv, index + 1, eolDelimiterLength) === options.delimiter.eol) {\n                    index += options.delimiter.eol.length + 1; // Skip past EOL\n                }\n            }\n            else if (charBefore === options.delimiter.field && character === options.delimiter.wrap && charAfter === options.delimiter.eol) {\n                // We reached the start of a wrapped new field that begins with an EOL delimiter\n                // Retrieve the remaining value and add it to the split line list of values\n                splitLine.push(csv.substring(stateVariables.startIndex, index - 1));\n                stateVariables.startIndex = index;\n                stateVariables.parsingValue = true;\n                stateVariables.insideWrapDelimiter = true;\n                stateVariables.justParsedDoubleQuote = true;\n                index += 1;\n            }\n            else if ((charBefore !== options.delimiter.wrap || stateVariables.justParsedDoubleQuote && charBefore === options.delimiter.wrap) &&\n                character === options.delimiter.wrap && utils.getNCharacters(csv, index + 1, eolDelimiterLength) === options.delimiter.eol) {\n                // If we reach a wrap which is not preceded by a wrap delim and the next character is an EOL delim (ie. *\"\\n)\n                stateVariables.insideWrapDelimiter = false;\n                stateVariables.parsingValue = false;\n                // Next iteration will substring, add the value to the line, and push the line onto the array of lines\n            }\n            else if (character === options.delimiter.wrap && (index === 0 || utils.getNCharacters(csv, index - eolDelimiterLength, eolDelimiterLength) === options.delimiter.eol && !stateVariables.insideWrapDelimiter)) {\n                // If the line starts with a wrap delimiter (ie. \"*)\n                stateVariables.insideWrapDelimiter = true;\n                stateVariables.parsingValue = true;\n                stateVariables.startIndex = index;\n            }\n            else if (character === options.delimiter.wrap && charAfter === options.delimiter.field && stateVariables.insideWrapDelimiter) {\n                // If we reached a wrap delimiter with a field delimiter after it (ie. *\",)\n                splitLine.push(csv.substring(stateVariables.startIndex, index + 1));\n                stateVariables.startIndex = index + 2; // next value starts after the field delimiter\n                stateVariables.insideWrapDelimiter = false;\n                stateVariables.parsingValue = false;\n            }\n            else if (character === options.delimiter.wrap && charBefore === options.delimiter.field &&\n                !stateVariables.insideWrapDelimiter && stateVariables.parsingValue) {\n                // If we reached a wrap delimiter with a field delimiter after it (ie. ,\"*)\n                splitLine.push(csv.substring(stateVariables.startIndex, index - 1));\n                stateVariables.insideWrapDelimiter = true;\n                stateVariables.parsingValue = true;\n                stateVariables.startIndex = index;\n            }\n            else if (character === options.delimiter.wrap && charAfter === options.delimiter.wrap && index !== stateVariables.startIndex) {\n                // If we run into an escaped quote (ie. \"\") skip past the second quote\n                index += 2;\n                stateVariables.justParsedDoubleQuote = true;\n                continue;\n            }\n            else if (character === options.delimiter.field && charBefore !== options.delimiter.wrap &&\n                charAfter !== options.delimiter.wrap && !stateVariables.insideWrapDelimiter &&\n                stateVariables.parsingValue) {\n                // If we reached a field delimiter and are not inside the wrap delimiters (ie. *,*)\n                splitLine.push(csv.substring(stateVariables.startIndex, index));\n                stateVariables.startIndex = index + 1;\n            }\n            else if (character === options.delimiter.field && charBefore === options.delimiter.wrap &&\n                charAfter !== options.delimiter.wrap && !stateVariables.parsingValue) {\n                // If we reached a field delimiter, the previous character was a wrap delimiter, and the\n                //   next character is not a wrap delimiter (ie. \",*)\n                stateVariables.insideWrapDelimiter = false;\n                stateVariables.parsingValue = true;\n                stateVariables.startIndex = index + 1;\n            }\n            // Otherwise increment to the next character\n            index++;\n            // Reset the double quote state variable\n            stateVariables.justParsedDoubleQuote = false;\n        }\n        return lines;\n    }\n    /**\n     * Retrieves the record lines from the split CSV lines and sets it on the params object\n     */\n    function retrieveRecordLines(params) {\n        if (options.headerFields) { // This option is passed for instances where the CSV has no header line\n            params.recordLines = params.lines;\n        }\n        else { // All lines except for the header line\n            params.recordLines = params.lines.splice(1);\n        }\n        return params;\n    }\n    /**\n     * Retrieves the value for the record from the line at the provided key.\n     */\n    function retrieveRecordValueFromLine(headerField, line) {\n        // If there is a value at the key's index, use it; otherwise, null\n        const value = line[headerField.index];\n        // Perform any necessary value conversions on the record value\n        return processRecordValue(value);\n    }\n    /**\n     * Processes the record's value by parsing the data to ensure the CSV is\n     * converted to the JSON that created it.\n     */\n    function processRecordValue(fieldValue) {\n        // If the value is an array representation, convert it\n        const parsedJson = parseValue(fieldValue);\n        // If parsedJson is anything aside from an error, then we want to use the parsed value\n        // This allows us to interpret values like 'null' --> null, 'false' --> false\n        if (!utils.isError(parsedJson) && !utils.isInvalid(parsedJson)) {\n            return parsedJson;\n        }\n        else if (fieldValue === 'undefined') {\n            return undefined;\n        }\n        return fieldValue;\n    }\n    /**\n     * Trims the record value, if specified by the user via the options object\n     */\n    function trimRecordValue(fieldValue) {\n        if (options.trimFieldValues && fieldValue !== null) {\n            return fieldValue.trim();\n        }\n        return fieldValue;\n    }\n    /**\n     * Create a JSON document with the given keys (designated by the CSV header)\n     *   and the values (from the given line)\n     * @returns {Object} created json document\n     */\n    function createDocument(headerFields, line) {\n        // Reduce the keys into a JSON document representing the given line\n        return headerFields.reduce((document, headerField) => {\n            // If there is a value at the key's index in the line, set the value; otherwise null\n            const value = retrieveRecordValueFromLine(headerField, line);\n            try {\n                // Otherwise add the key and value to the document\n                return (0, doc_path_1.setPath)(document, headerField.value, value);\n            }\n            catch (error) {\n                // Catch any errors where key paths are null or '' and continue\n                return document;\n            }\n        }, {});\n    }\n    /**\n     * Removes the outermost wrap delimiters from a value, if they are present\n     * Otherwise, the non-wrapped value is returned as is\n     */\n    function removeWrapDelimitersFromValue(fieldValue) {\n        const firstChar = fieldValue[0], lastIndex = fieldValue.length - 1, lastChar = fieldValue[lastIndex];\n        // If the field starts and ends with a wrap delimiter\n        if (firstChar === options.delimiter.wrap && lastChar === options.delimiter.wrap) {\n            // Handle the case where the field is just a pair of wrap delimiters \n            return fieldValue.length <= 2 ? '' : fieldValue.substring(1, lastIndex);\n        }\n        return fieldValue;\n    }\n    /**\n     * Unescapes wrap delimiters by replacing duplicates with a single (eg. \"\" -> \")\n     * This is done in order to parse RFC 4180 compliant CSV back to JSON\n     */\n    function unescapeWrapDelimiterInField(fieldValue) {\n        return fieldValue.replace(escapedWrapDelimiterRegex, options.delimiter.wrap);\n    }\n    /**\n     * Main helper function to convert the CSV to the JSON document array\n     */\n    function transformRecordLines(params) {\n        // For each line, create the document and add it to the array of documents\n        return params.recordLines.reduce((generatedJsonObjects, line) => {\n            line = line.map((fieldValue) => {\n                // Perform the necessary operations on each line\n                fieldValue = removeWrapDelimitersFromValue(fieldValue);\n                fieldValue = unescapeWrapDelimiterInField(fieldValue);\n                fieldValue = trimRecordValue(fieldValue);\n                return fieldValue;\n            });\n            const generatedDocument = createDocument(params.headerFields, line);\n            return generatedJsonObjects.concat(generatedDocument);\n        }, []);\n    }\n    /**\n     * Attempts to parse the provided value. If it is not parsable, then an error is returned\n     */\n    function parseValue(value) {\n        try {\n            if (utils.isStringRepresentation(value, options) && !utils.isDateRepresentation(value)) {\n                return value;\n            }\n            const parsedJson = valueParserFn(value);\n            // If the parsed value is an array, then we also need to trim record values, if specified\n            if (Array.isArray(parsedJson)) {\n                return parsedJson.map(trimRecordValue);\n            }\n            return parsedJson;\n        }\n        catch (err) {\n            return err;\n        }\n    }\n    /**\n     * Internally exported csv2json function\n     */\n    function convert(data) {\n        // Split the CSV into lines using the specified EOL option\n        const stripped = stripExcelBOM(data);\n        const split = splitLines(stripped);\n        const heading = retrieveHeading(split); // Retrieve the headings from the CSV, unless the user specified the keys\n        const lines = retrieveRecordLines(heading); // Retrieve the record lines from the CSV\n        return transformRecordLines(lines); // Retrieve the JSON document array\n    }\n    return {\n        convert,\n    };\n};\nexports.Csv2Json = Csv2Json;\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isDocumentToRecurOn = exports.flatten = exports.unique = void 0;\nfunction unique(array) {\n    return [...new Set(array)];\n}\nexports.unique = unique;\nfunction flatten(array) {\n    return [].concat(...array);\n}\nexports.flatten = flatten;\n/**\n * Returns whether this value is a document to recur on or not\n * @param val Any item whose type will be evaluated\n * @returns {boolean}\n */\nfunction isDocumentToRecurOn(val) {\n    return typeof val === 'object' && val !== null && !Array.isArray(val) && Object.keys(val).length;\n}\nexports.isDocumentToRecurOn = isDocumentToRecurOn;\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isInvalid = exports.flatten = exports.unique = exports.arrayDifference = exports.isError = exports.isUndefined = exports.isNull = exports.isObject = exports.isString = exports.isNumber = exports.unwind = exports.getNCharacters = exports.removeEmptyFields = exports.isEmptyField = exports.computeSchemaDifferences = exports.isDateRepresentation = exports.isStringRepresentation = exports.deepCopy = exports.validate = exports.buildC2JOptions = exports.buildJ2COptions = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst constants_1 = require(\"./constants\");\nconst dateStringRegex = /\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}.\\d{3}Z/, MAX_ARRAY_LENGTH = 100000;\n/**\n * Build the options to be passed to the appropriate function\n * If a user does not provide custom options, then we use our default\n * If options are provided, then we set each valid key that was passed\n */\nfunction buildJ2COptions(opts) {\n    return {\n        ...constants_1.defaultJson2CsvOptions,\n        ...opts,\n        delimiter: {\n            field: opts?.delimiter?.field ?? constants_1.defaultJson2CsvOptions.delimiter.field,\n            wrap: opts?.delimiter?.wrap || constants_1.defaultJson2CsvOptions.delimiter.wrap,\n            eol: opts?.delimiter?.eol || constants_1.defaultJson2CsvOptions.delimiter.eol,\n        },\n        fieldTitleMap: opts?.fieldTitleMap || Object.create({}),\n    };\n}\nexports.buildJ2COptions = buildJ2COptions;\n/**\n * Build the options to be passed to the appropriate function\n * If a user does not provide custom options, then we use our default\n * If options are provided, then we set each valid key that was passed\n */\nfunction buildC2JOptions(opts) {\n    return {\n        ...constants_1.defaultCsv2JsonOptions,\n        ...opts,\n        delimiter: {\n            field: opts?.delimiter?.field ?? constants_1.defaultCsv2JsonOptions.delimiter.field,\n            wrap: opts?.delimiter?.wrap || constants_1.defaultCsv2JsonOptions.delimiter.wrap,\n            eol: opts?.delimiter?.eol || constants_1.defaultCsv2JsonOptions.delimiter.eol,\n        },\n    };\n}\nexports.buildC2JOptions = buildC2JOptions;\nfunction validate(data, validationFn, errorMessages) {\n    if (!data)\n        throw new Error(`${errorMessages.cannotCallOn} ${data}.`);\n    if (!validationFn(data))\n        throw new Error(errorMessages.dataCheckFailure);\n    return true;\n}\nexports.validate = validate;\n/**\n * Utility function to deep copy an object, used by the module tests\n */\nfunction deepCopy(obj) {\n    return JSON.parse(JSON.stringify(obj));\n}\nexports.deepCopy = deepCopy;\n/**\n * Helper function that determines whether the provided value is a representation\n *   of a string. Given the RFC4180 requirements, that means that the value is\n *   wrapped in value wrap delimiters (usually a quotation mark on each side).\n */\nfunction isStringRepresentation(fieldValue, options) {\n    const firstChar = fieldValue[0], lastIndex = fieldValue.length - 1, lastChar = fieldValue[lastIndex];\n    // If the field starts and ends with a wrap delimiter\n    return firstChar === options.delimiter.wrap && lastChar === options.delimiter.wrap;\n}\nexports.isStringRepresentation = isStringRepresentation;\n/**\n * Helper function that determines whether the provided value is a representation\n *   of a date.\n */\nfunction isDateRepresentation(fieldValue) {\n    return dateStringRegex.test(fieldValue);\n}\nexports.isDateRepresentation = isDateRepresentation;\n/**\n * Helper function that determines the schema differences between two objects.\n */\nfunction computeSchemaDifferences(schemaA, schemaB) {\n    return arrayDifference(schemaA, schemaB)\n        .concat(arrayDifference(schemaB, schemaA));\n}\nexports.computeSchemaDifferences = computeSchemaDifferences;\n/**\n * Utility function to check if a field is considered empty so that the emptyFieldValue can be used instead\n */\nfunction isEmptyField(fieldValue) {\n    return isUndefined(fieldValue) || isNull(fieldValue) || fieldValue === '';\n}\nexports.isEmptyField = isEmptyField;\n/**\n * Helper function that removes empty field values from an array.\n */\nfunction removeEmptyFields(fields) {\n    return fields.filter((field) => !isEmptyField(field));\n}\nexports.removeEmptyFields = removeEmptyFields;\n/**\n * Helper function that retrieves the next n characters from the start index in\n *   the string including the character at the start index. This is used to\n *   check if are currently at an EOL value, since it could be multiple\n *   characters in length (eg. '\\r\\n')\n */\nfunction getNCharacters(str, start, n) {\n    return str.substring(start, start + n);\n}\nexports.getNCharacters = getNCharacters;\n/**\n * The following unwind functionality is a heavily modified version of @edwincen's\n * unwind extension for lodash. Since lodash is a large package to require in,\n * and all of the required functionality was already being imported, either\n * natively or with doc-path, I decided to rewrite the majority of the logic\n * so that an additional dependency would not be required. The original code\n * with the lodash dependency can be found here:\n *\n * https://github.com/edwincen/unwind/blob/master/index.js\n */\n/**\n * Core function that unwinds an item at the provided path\n */\nfunction unwindItem(accumulator, item, fieldPath) {\n    const valueToUnwind = (0, doc_path_1.evaluatePath)(item, fieldPath);\n    let cloned = deepCopy(item);\n    if (Array.isArray(valueToUnwind) && valueToUnwind.length) {\n        valueToUnwind.forEach((val) => {\n            cloned = deepCopy(item);\n            accumulator.push((0, doc_path_1.setPath)(cloned, fieldPath, val));\n        });\n    }\n    else if (Array.isArray(valueToUnwind) && valueToUnwind.length === 0) {\n        // Push an empty string so the value is empty since there are no values\n        (0, doc_path_1.setPath)(cloned, fieldPath, '');\n        accumulator.push(cloned);\n    }\n    else {\n        accumulator.push(cloned);\n    }\n}\n/**\n * Main unwind function which takes an array and a field to unwind.\n */\nfunction unwind(array, field) {\n    const result = [];\n    array.forEach((item) => {\n        unwindItem(result, item, field);\n    });\n    return result;\n}\nexports.unwind = unwind;\n/**\n * Checks whether value can be converted to a number\n */\nfunction isNumber(value) {\n    return !isNaN(Number(value));\n}\nexports.isNumber = isNumber;\n/*\n * Helper functions which were created to remove underscorejs from this package.\n */\nfunction isString(value) {\n    return typeof value === 'string';\n}\nexports.isString = isString;\nfunction isObject(value) {\n    return typeof value === 'object';\n}\nexports.isObject = isObject;\nfunction isNull(value) {\n    return value === null;\n}\nexports.isNull = isNull;\nfunction isUndefined(value) {\n    return typeof value === 'undefined';\n}\nexports.isUndefined = isUndefined;\nfunction isError(value) {\n    // TODO(mrodrig): test this possible change\n    // return value instanceof Error;\n    return Object.prototype.toString.call(value) === '[object Error]';\n}\nexports.isError = isError;\nfunction arrayDifference(a, b) {\n    return a.filter((x) => !b.includes(x));\n}\nexports.arrayDifference = arrayDifference;\nfunction unique(array) {\n    return [...new Set(array)];\n}\nexports.unique = unique;\nfunction flatten(array) {\n    // Node 11+ - use the native array flattening function\n    if (array.flat) {\n        return array.flat();\n    }\n    // #167 - allow browsers to flatten very long 200k+ element arrays\n    if (array.length > MAX_ARRAY_LENGTH) {\n        let safeArray = [];\n        for (let a = 0; a < array.length; a += MAX_ARRAY_LENGTH) {\n            safeArray = safeArray.concat(...array.slice(a, a + MAX_ARRAY_LENGTH));\n        }\n        return safeArray;\n    }\n    return array.reduce((accumulator, value) => accumulator.concat(value), []);\n}\nexports.flatten = flatten;\n/**\n * Used to help avoid incorrect values returned by JSON.parse when converting\n * CSV back to JSON, such as '39e1804' which JSON.parse converts to Infinity\n */\nfunction isInvalid(parsedJson) {\n    return parsedJson === Infinity ||\n        parsedJson === -Infinity;\n}\nexports.isInvalid = isInvalid;\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.excelBOM = exports.defaultCsv2JsonOptions = exports.defaultJson2CsvOptions = exports.errors = void 0;\nexports.errors = {\n    optionsRequired: 'Options were not passed and are required.',\n    json2csv: {\n        cannotCallOn: 'Cannot call json2csv on',\n        dataCheckFailure: 'Data provided was not an array of documents.',\n        notSameSchema: 'Not all documents have the same schema.'\n    },\n    csv2json: {\n        cannotCallOn: 'Cannot call csv2json on',\n        dataCheckFailure: 'CSV is not a string.'\n    }\n};\nexports.defaultJson2CsvOptions = {\n    arrayIndexesAsKeys: false,\n    checkSchemaDifferences: false,\n    delimiter: {\n        field: ',',\n        wrap: '\"',\n        eol: '\\n'\n    },\n    emptyFieldValue: undefined,\n    escapeHeaderNestedDots: true,\n    excelBOM: false,\n    excludeKeys: [],\n    expandNestedObjects: true,\n    expandArrayObjects: false,\n    prependHeader: true,\n    preventCsvInjection: false,\n    sortHeader: false,\n    trimFieldValues: false,\n    trimHeaderFields: false,\n    unwindArrays: false,\n    useDateIso8601Format: false,\n    useLocaleFormat: false,\n    wrapBooleans: false,\n    fieldTitleMap: Object.create({}),\n};\nexports.defaultCsv2JsonOptions = {\n    delimiter: {\n        field: ',',\n        wrap: '\"',\n        eol: '\\n'\n    },\n    excelBOM: false,\n    preventCsvInjection: false,\n    trimFieldValues: false,\n    trimHeaderFields: false,\n};\nexports.excelBOM = '\\ufeff';\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8]}